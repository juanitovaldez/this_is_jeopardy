{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T23:42:15.035056Z",
     "start_time": "2019-11-19T23:42:13.271744Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install d6tstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Jeopardy!\n",
    "We're going to load up some jeopardy clues into a postgres database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T23:42:33.342078Z",
     "start_time": "2019-11-19T23:42:20.024331Z"
    }
   },
   "outputs": [],
   "source": [
    "# First we will import the things we need to make a connection to server\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import sqlalchemy\n",
    "import postgres_config as pcfg\n",
    "from sqlalchemy import create_engine\n",
    "import d6tstack\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "cnx = create_engine(pcfg.pg_engine_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database design:\n",
    "Before we go further we need to answer some questions about the data.\n",
    "1. How is it coming in to us?\n",
    "   - We have an option of a series of CSV's \n",
    "   - OR we have a single large json with maybe less header info\n",
    "2. What will constitute a unique primary key?\n",
    "    - In light of possible near collisions it might be best to consider the next option\n",
    "3. Will we have to create a unique hash_id\n",
    "    - luckily postgres has a way of doing this\n",
    "4. What kind of relationships are there between tables?\n",
    "    -\n",
    "5. Is there any advantage of having the data in separate tables or would having a giant table with all the files appended on to it be the way to go?\n",
    "6. What other data can we querry against this data base?\n",
    "7. What hints and fields can we find correlations with outside of the scope of our dataset?\n",
    "8. What are the columns and data types? do they vary from file to file? what about the json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T00:38:52.351678Z",
     "start_time": "2019-11-20T00:38:52.346185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Well let's get into it. We'll make a table using sqlaclhemy and try to import one file into it\n",
    "# Going to try and use a new tool to avoid using the sloppy mess of code i wrote to\n",
    "# ingest csv files: d6tstacks promises to solve data ingestion issues we'll see.\n",
    "# I'll be leaning on their example notbook\n",
    "\n",
    "jeopardy_fnames = [f for f in glob.glob(\"../this_is_jeopardy/**/*.tsv\", recursive=True)]\n",
    "print(jeopardy_fnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
